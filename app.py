import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import time
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from imblearn.over_sampling import SMOTE
import shap
from lime.lime_tabular import LimeTabularExplainer
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from scipy.stats import shapiro
import io

# ---------------- Configura√ß√£o est√©tica ----------------
st.set_page_config(page_title="An√°lise de Clientes", page_icon="üíº", layout="wide")

st.title("üìä Relat√≥rio de Inten√ß√£o de Compra Online")
st.markdown("Interface profissional com m√©tricas, gr√°ficos e explicabilidade")

# ---------------- Sidebar ----------------
st.sidebar.image("https://cdn-icons-png.flaticon.com/512/3135/3135715.png", width=100)
st.sidebar.title("Configura√ß√µes")

arquivo = st.sidebar.file_uploader("Carregar arquivo (CSV ou XLSX)", type=["csv","xlsx"])
alvo = st.sidebar.text_input("Vari√°vel alvo", "Revenue")
modelo_escolhido = st.sidebar.selectbox("Modelo", ["Regress√£o Log√≠stica", "Random Forest", "XGBoost"])

# ---------------- Fun√ß√µes auxiliares ----------------
@st.cache_data
def carregar_dados(arquivo):
    if arquivo.name.endswith(".csv"):
        return pd.read_csv(arquivo)
    else:
        return pd.read_excel(arquivo)

def avaliar(modelo, X_teste, y_teste):
    y_pred = modelo.predict(X_teste)
    y_proba = modelo.predict_proba(X_teste)[:,1]
    return {
        "Acur√°cia": accuracy_score(y_teste, y_pred),
        "Precis√£o": precision_score(y_teste, y_pred),
        "Recall": recall_score(y_teste, y_pred),
        "F1": f1_score(y_teste, y_pred),
        "AUC": roc_auc_score(y_teste, y_proba)
    }

# ---------------- Pipeline ----------------
if arquivo:
    dados = carregar_dados(arquivo)

    # Tradu√ß√£o de colunas
    traducao = {"Revenue":"Compra","BounceRates":"TaxaRejei√ß√£o","ExitRates":"TaxaSa√≠da",
                "PageValues":"ValorP√°gina","SpecialDay":"DiaEspecial","Month":"M√™s",
                "OperatingSystems":"SistemaOperacional","Browser":"Navegador","Region":"Regi√£o",
                "TrafficType":"TipoTr√°fego","VisitorType":"TipoVisitante","Weekend":"FimDeSemana"}
    dados = dados.rename(columns=traducao)

    X = dados.drop(columns=["Compra"])
    y = dados["Compra"].astype(int)

    colunas_num = X.select_dtypes(include=[float,int]).columns.tolist()
    colunas_cat = X.select_dtypes(exclude=[float,int]).columns.tolist()

    preprocessador = ColumnTransformer([
        ("num", StandardScaler(), colunas_num),
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), colunas_cat)
    ])

    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
    X_train_proc = preprocessador.fit_transform(X_train)
    X_test_proc = preprocessador.transform(X_test)

    smote = SMOTE(random_state=42)
    X_train_bal, y_train_bal = smote.fit_resample(X_train_proc, y_train)

    # ---------------- Tabs ----------------
    tab1, tab2, tab3, tab4 = st.tabs(["Explora√ß√£o", "Modelagem", "Valida√ß√£o", "Resultados"])

    # -------- Tab 1: EDA --------
    with tab1:
        st.subheader("üìä An√°lise Explorat√≥ria")
        st.plotly_chart(px.histogram(dados, x="ValorP√°gina", color="Compra"))
        st.plotly_chart(px.box(dados, x="Compra", y="TaxaRejei√ß√£o"))
        fig_corr = px.imshow(dados[colunas_num].corr(), text_auto=True, color_continuous_scale="Blues")
        st.plotly_chart(fig_corr)

    # -------- Tab 2: Modelagem --------
    with tab2:
        if modelo_escolhido == "Regress√£o Log√≠stica":
            modelo = LogisticRegression(max_iter=1000)
        elif modelo_escolhido == "Random Forest":
            param_grid = {'n_estimators':[100,200,300],'max_depth':[None,5,10],'min_samples_split':[2,5,10]}
            search = RandomizedSearchCV(RandomForestClassifier(random_state=42),
                                        param_grid, n_iter=5, cv=3, scoring="roc_auc")
            search.fit(X_train_bal, y_train_bal)
            modelo = search.best_estimator_
            st.write("üîß Melhor conjunto de hiperpar√¢metros:", search.best_params_)
        else:
            modelo = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42)

        modelo.fit(X_train_bal, y_train_bal)
        resultados = avaliar(modelo, X_test_proc, y_test)

        st.subheader("üìà M√©tricas do Modelo")
        st.write(pd.DataFrame([resultados]))

        fig, ax = plt.subplots(figsize=(6,4))
        sns.barplot(x=list(resultados.keys()), y=list(resultados.values()), palette="Blues", ax=ax)
        ax.set_title("Desempenho do Modelo", fontsize=14)
        st.pyplot(fig)

    # -------- Tab 3: Valida√ß√£o --------
    with tab3:
        st.subheader("üìä Testes Estat√≠sticos")

        # VIF
        vif_data = pd.DataFrame()
        vif_data["feature"] = colunas_num
        vif_data["VIF"] = [variance_inflation_factor(X_train[colunas_num].values, i)
                           for i in range(len(colunas_num))]
        st.write("Multicolinearidade (VIF):")
        st.write(vif_data)

        # Normalidade dos res√≠duos
        residuos = y_test - modelo.predict(X_test_proc)
        stat, p = shapiro(residuos)
        st.write(f"Normalidade dos res√≠duos (Shapiro-Wilk): p-valor={p:.4f}")

        # Homoscedasticidade (Breusch-Pagan) com constante
        X_test_bp = sm.add_constant(X_test_proc)
        bp_test = sm.stats.diagnostic.het_breuschpagan(residuos, X_test_bp)
        st.write(f"Homoscedasticidade (Breusch-Pagan): estat√≠stica={bp_test[0]:.3f}, p-valor={bp_test[1]:.4f}")

    # -------- Tab 4: Resultados --------
  
    with tab4:
        st.subheader("üìä Compara√ß√£o de Modelos")
        resultados_modelos = {}
        for nome, modelo_cls in {
            "Regress√£o Log√≠stica": LogisticRegression(max_iter=1000),
            "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
            "XGBoost": XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42)
        }.items():
            inicio = time.time()
            modelo_cls.fit(X_train_bal, y_train_bal)
            fim = time.time()
            resultados_modelos[nome] = avaliar(modelo_cls, X_test_proc, y_test)
            resultados_modelos[nome]["TempoTreino"] = fim - inicio
        st.write(pd.DataFrame(resultados_modelos).T)

        # Explicabilidade SHAP
        st.subheader("üîç Explicabilidade (SHAP)")
        if modelo_escolhido in ["Random Forest", "XGBoost"]:
            explainer = shap.TreeExplainer(modelo)
            shap_values = explainer.shap_values(X_test_proc)
            st.write("Resumo das vari√°veis mais influentes:")
            shap.summary_plot(
                shap_values, X_test_proc,
                feature_names=np.concatenate([
                    colunas_num,
                    preprocessador.named_transformers_["cat"].get_feature_names_out(colunas_cat)
                ])
            )
        else:
            st.warning("O modelo selecionado n√£o √© compat√≠vel com SHAP TreeExplainer.")

        # Explicabilidade LIME
        st.subheader("üîç Explicabilidade (LIME)")
        lime_explainer = LimeTabularExplainer(
            training_data=np.array(X_train_bal),
            feature_names=np.concatenate([
                colunas_num,
                preprocessador.named_transformers_["cat"].get_feature_names_out(colunas_cat)
            ]),
            class_names=["N√£o Compra","Compra"],
            mode="classification"
        )
        exp = lime_explainer.explain_instance(X_test_proc[10], modelo.predict_proba, num_features=10)
        st.write("Exemplo de explica√ß√£o local (inst√¢ncia 10):")
        st.write(exp.as_list())

        # üìÑ Relat√≥rio Executivo
        st.subheader("üìÑ Relat√≥rio Executivo")
        relatorio = f"""
        Modelo selecionado: **{modelo_escolhido}**

        Principais m√©tricas:
        - Acur√°cia: {resultados['Acur√°cia']:.3f} ‚Üí O modelo acerta {resultados['Acur√°cia']*100:.1f}% das previs√µes.
        - Precis√£o: {resultados['Precis√£o']:.3f} ‚Üí Apenas {resultados['Precis√£o']*100:.1f}% dos casos previstos como compra realmente compram.
        - Recall: {resultados['Recall']:.3f} ‚Üí O modelo captura {resultados['Recall']*100:.1f}% dos clientes que compram.
        - F1: {resultados['F1']:.3f} ‚Üí Equil√≠brio moderado entre precis√£o e recall.
        - AUC: {resultados['AUC']:.3f} ‚Üí Excelente capacidade de discrimina√ß√£o.

        Vari√°veis mais influentes:
        - ValorP√°gina: p√°ginas com alto valor aumentam chance de compra.
        - TaxaRejei√ß√£o: altas taxas reduzem probabilidade de compra.
        - DiaEspecial: datas pr√≥ximas a eventos especiais elevam convers√£o.

        üìå Interpreta√ß√£o executiva:
        O modelo √© eficaz para identificar potenciais compradores, especialmente em campanhas amplas.
        No entanto, a precis√£o baixa indica risco de falsos positivos, sugerindo ajustes para reduzir custos em a√ß√µes direcionadas.

        üéØ Recomenda√ß√µes:
        - Focar campanhas em clientes que acessam p√°ginas de alto valor.
        - Aproveitar datas especiais para aumentar convers√£o.
        - Monitorar taxa de rejei√ß√£o como indicador de desist√™ncia.
        """
        st.text_area("Resumo Executivo", relatorio, height=350)